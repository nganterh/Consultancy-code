{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, Comment\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "geckodriver_path = r'C:\\Users\\nicol\\anaconda3\\Library\\bin\\geckodriver'\n",
    "browser = webdriver.Firefox(executable_path=geckodriver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "competitors = pd.read_excel(f'{os.getcwd()}\\\\Libro1.xlsx', engine=\"openpyxl\", index_col=0)\n",
    "                            #usecols=['ID', 'Relación', 'Tópicos', 'Nombre', 'Comuna', 'Cuenta con clases online',\n",
    "                            #         'Cuenta con clases presenciales', 'Instagram', 'has_instagram',\n",
    "                            #         'Publicaciones', 'Norm Publicaciones', 'Seguidores Instagram',\n",
    "                            #         'Norm Seguidores', 'Seguidos', 'Página web'])\n",
    "\n",
    "display(competitors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Instagram</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(range(competitors.shape[0])):\n",
    "    new_cols = ['Publicaciones', 'Seguidores', 'Seguidos']\n",
    "    url = competitors.at[row, 'Instagram']\n",
    "    \n",
    "    try:\n",
    "        browser.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        html_instagram = browser.page_source\n",
    "        soup_instagram = BeautifulSoup(html_instagram, 'lxml')\n",
    "\n",
    "        elements = soup_instagram.find_all('a', class_ = '-nal3')\n",
    "        \n",
    "        for i, element in enumerate(elements):\n",
    "            re_element = re.search('([0-9]\\,[0-9]|[0-9]\\.[0-9]]+)', element.text)#.group(1)\n",
    "            raw_number = re_element.group(1)\n",
    "            \n",
    "            number_commas = raw_number.replace(',', '')\n",
    "            clean_number = raw_number.replace('.', '')\n",
    "            \n",
    "            \n",
    "            \n",
    "            try:\n",
    "                multiplier = re_element.group(2)\n",
    "                number = clean_number * 1000\n",
    "            \n",
    "            except:\n",
    "                number = clean_number              \n",
    "                \n",
    "            try:\n",
    "                competitors.at[row, new_cols[i]] = number.text\n",
    "                \n",
    "            except:\n",
    "                competitors[new_cols[i]] = None\n",
    "                competitors.at[row, new_cols[i]] = number.text\n",
    "            \n",
    "    except Exception as e:\n",
    "        for col in new_cols:\n",
    "            competitors.at[row, col] = None\n",
    "    \n",
    "    print(re_element)        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(competitors)#.to_excel('cacapoto.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Facebook</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(range(competitors.shape[0])):\n",
    "    new_cols = ['Seguidores Instagram', 'Me gusta']\n",
    "    url = competitors.at[row, 'Facebook']\n",
    "    \n",
    "    try:\n",
    "        html_facebook = requests.get(url)\n",
    "        soup_facebook = BeautifulSoup(html_facebook.text, 'lxml')\n",
    "\n",
    "        seguidores = re.search('([0-9\\.]+) personas siguen esto', html_facebook.text).group(1)\n",
    "        me_gusta = re.search('A ([0-9\\.]+) personas les gusta esto', html_facebook.text).group(1)\n",
    "        #estuvieron = re.search('([0-9\\.]+) personas estuvieron aquí', html_facebook.text).group(1)\n",
    "\n",
    "        #print(f'Seguidores: {seguidores}'.replace('.', ''), '\\n'\n",
    "        #      f'Me gusta: {me_gusta}'.replace('.', ''), '\\n')#,\n",
    "              #f'Asistentes: {estuvieron}'.replace('.', ''), '\\n')\n",
    "\n",
    "        try:\n",
    "            competitors.at[row, 'Seguidores Instagram'] = seguidores.replace('.', '')\n",
    "            competitors.at[row, 'Me gusta'] = me_gusta.replace('.', '')\n",
    "\n",
    "        except:\n",
    "            competitors[new_cols[i]] = None\n",
    "            competitors.at[row, 'Seguidores Instagram'] = seguidores.replace('.', '')\n",
    "            competitors.at[row, 'Me gusta'] = me_gusta.replace('.', '')\n",
    "            \n",
    "    except Exception as e:\n",
    "        for col in new_cols:\n",
    "            competitors.at[row, col] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors.to_excel('cacapoto.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Youtube</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(range(competitors.shape[0])):\n",
    "    new_cols = ['Suscriptores']\n",
    "    url = competitors.at[row, 'Youtube']\n",
    "\n",
    "    try:\n",
    "        html_youtube = requests.get(url)\n",
    "        #soup_youtube = BeautifulSoup(html_youtube.text, 'lxml')\n",
    "\n",
    "        subscribers = re.search('([0-9\\.]+) suscriptores', html_youtube.text).group(1)\n",
    "        #print(f'Suscriptores: {subscribers}')\n",
    "    \n",
    "        try:\n",
    "            competitors.at[row, 'Suscriptores'] = subscribers.replace('.', '')\n",
    "\n",
    "        except:\n",
    "            competitors[new_cols[i]] = None\n",
    "            competitors.at[row, 'Suscriptores'] = subscribers.replace('.', '')\n",
    "            \n",
    "    except Exception as e:\n",
    "        for col in new_cols:\n",
    "            competitors.at[row, 'Suscriptores'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors.to_excel('cacapoto.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Twitter</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for row in tqdm(range(competitors.shape[0])):\n",
    "#    new_cols = ['Suscriptores']\n",
    "#    url = competitors.at[row, 'Twitter']\n",
    "    \n",
    "browser.get('https://twitter.com/Danaamar')\n",
    "time.sleep(5)\n",
    "\n",
    "html_twitter = browser.page_source\n",
    "soup_twitter = BeautifulSoup(html_twitter, 'lxml')\n",
    "\n",
    "#following = re.search('([0-9\\.]+) personas siguen esto', html_twitter).group(1)\n",
    "#followers = re.search('([0-9\\.]+) personas siguen esto', html_twitter).group(1)\n",
    "\n",
    "#print(following, followers, '\\n\\n', soup_twitter.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_twitter.select('//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div/div[1]/div/div[2]/div/div/div[1]/div/div[5]/div[1]/a/span[1]/span')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Webpage</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(basic_url, browser):\n",
    "    #html_webpage = requests.get(basic_url)\n",
    "    browser.get(basic_url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    html_webpage = browser.page_source\n",
    "    soup_webpage = BeautifulSoup(html_webpage, 'lxml') #.content, 'lxml')\n",
    "\n",
    "    raw_links = set([re.search(f'{basic_url}(.*)', f'{basic_url}{tag.get(\"href\")}').group(1)\n",
    "                     for tag in soup_webpage.find_all('a')] + [basic_url])\n",
    "    \n",
    "    forbidden = ['facebook', 'youtube', 'vimeo', 'instagram', 'outlook', 'whatsapp', 'twitter', 'linkedin']\n",
    "    links = []\n",
    "    \n",
    "    for link in raw_links:\n",
    "        check = 0\n",
    "\n",
    "        for page in forbidden:\n",
    "\n",
    "            try:\n",
    "                re_test = re.search(f'({page})', link).group(1)\n",
    "                check += 1\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                file_name = re.search('(https://www\\.|http://www\\.|https://|http://)(.*)\\.', link).group(2)\n",
    "\n",
    "            except:\n",
    "                check += 1\n",
    "\n",
    "        if check == 0:\n",
    "            links.append(link)\n",
    "    \n",
    "    set_links = set(links)\n",
    "\n",
    "    dict_texts = {}\n",
    "    dict_clean = {'á': 'a', 'é': 'e','í': 'i', 'ó': 'o', 'ú':'u', '.': '', ',': ' '}\n",
    "    prohibited = ['facebook', 'twitter', 'youtube', 'redes', 'sociales', 'videos',\n",
    "                  'home', 'contacto', 'noticias', 'navegacion', 'enlace']\n",
    "\n",
    "    for link in set_links:\n",
    "        list_text = []\n",
    "\n",
    "        try:\n",
    "            #html_link = requests.get(link)\n",
    "            browser.get(link)\n",
    "            time.sleep(3)\n",
    "            \n",
    "            html_link = browser.page_source\n",
    "            soup_link = BeautifulSoup(html_link, 'lxml') #.content, 'lxml')\n",
    "\n",
    "            for text in soup_link.body.find_all(string=True):\n",
    "                if text.parent.name not in ['script', 'meta', 'link', 'style'] and not isinstance(text, Comment) and text != '\\n':\n",
    "                    list_text.append(text.strip())\n",
    "\n",
    "            raw_text = ','.join(list_text).lower()\n",
    "            clean_chars = ''.join([dict_clean[char] if char in dict_clean.keys() else char for char in raw_text ])\n",
    "            clean_words = ' '.join([word for word in clean_chars.split(' ') if word not in prohibited])\n",
    "            #print([word for word in clean_chars if word not in prohibited])\n",
    "\n",
    "            dict_texts[link] = clean_words\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    text = ', '.join(list(dict_texts.values()))\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 https://www.bellydancer.cl bellydancer 3864\n",
      "104 https://www.safidanzaarabe.com safidanzaarabe 10512\n",
      "105 https://www.bamboleo.cl bamboleo 2567\n",
      "106 https://lamorenetastudio.com lamorenetastudio 84116\n",
      "107 https://nataliadufuur.com nataliadufuur 128081\n",
      "108 https://www.artfitcenter.cl artfitcenter 42158\n",
      "109 https://danielabellydancer.com danielabellydancer 83147\n",
      "110 https://danson.cl danson 38946\n",
      "111 https://poledancetraining.cl poledancetraining 34333\n",
      "112 https://www.sandricastillo.com sandricastillo 9616\n",
      "113 http://www.danaamar.com danaamar 36927\n",
      "114 http://www.seyyalbellydancer.com seyyalbellydancer 143333\n",
      "115 http://www.nayra.cl nayra 0\n",
      "116 https://danzadelvientretribal.cl danzadelvientretribal 18832\n",
      "117 https://www.arabesca.cl arabesca 36753\n",
      "118 https://www.bailesvalero.cl bailesvalero 137218\n",
      "119 https://escueladeburlesquesantiago.cl escueladeburlesquesantiago 28454\n",
      "120 https://rumbachilena.cl rumbachilena 194527\n",
      "121 http://www.nurdeoriente.cl nurdeoriente 688\n",
      "122 https://www.euphoriadance.cl euphoriadance 21620\n",
      "123 https://clasessanmiguel.blogspot.com clasessanmiguel.blogspot 923805\n",
      "124 https://www.lovebellydanceonline.com lovebellydanceonline 13569\n",
      "125 http://www.bailemosalsa.cl bailemosalsa 3295\n",
      "126 http://natalia-abdallah.com natalia-abdallah 101157\n",
      "127 https://orientaldanceonline.com orientaldanceonline 14088\n",
      "128 http://leonorperez.cl leonorperez 269\n",
      "129 https://www.danzaire.cl danzaire 13898\n",
      "130 https://academiazamia.blogspot.com academiazamia.blogspot 19857\n",
      "131 http://danzaarabechile.cl danzaarabechile 247144\n",
      "132 https://www.clubluna.cl clubluna 494\n",
      "133 http://buscadanza.cl buscadanza 230870\n"
     ]
    }
   ],
   "source": [
    "### counter = 0\n",
    "dict_texts = {}\n",
    "\n",
    "for i, row in enumerate(competitors.index):\n",
    "    url = competitors.at[row, 'Página web']\n",
    "    \n",
    "    if isinstance(url, str):\n",
    "        basic_url = re.search('(.*\\.com|.*\\.cl)', url).group(1)\n",
    "        file_name = re.search('(https://www\\.|http://www\\.|https://|http://)(.*)\\.', basic_url).group(2)\n",
    "        text_in_url = get_text(basic_url, browser)\n",
    "        \n",
    "        dict_texts[file_name] = (len(text_in_url), text_in_url, basic_url)\n",
    "        print(counter, basic_url, file_name, len(text_in_url))\n",
    "        counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = ''.join([value[1] for value in dict_texts.values()])\n",
    "list_words = all_text.split(' ')\n",
    "\n",
    "df_test = pd.DataFrame({'words': list_words})\n",
    "df_uniques = pd.unique(df_test['words'])\n",
    "\n",
    "df_test.to_excel('test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>words</th>\n",
       "      <th>repetitions</th>\n",
       "      <th>lenght</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440787</th>\n",
       "      <td>438088</td>\n",
       "      <td>-70580343</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440788</th>\n",
       "      <td>438116</td>\n",
       "      <td>4792</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440789</th>\n",
       "      <td>438148</td>\n",
       "      <td>hcw9+8v</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0      words  repetitions  lenght\n",
       "440787      438088  -70580343            1       9\n",
       "440788      438116       4792            1       4\n",
       "440789      438148    hcw9+8v            1       7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test = pd.read_excel('test.xlsx', engine=\"openpyxl\")\n",
    "display(df_test.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272686\n"
     ]
    }
   ],
   "source": [
    "df_filter = df_test[df_test['lenght'] > 3]\n",
    "\n",
    "re_list = df_filter['words'].to_list()\n",
    "print(len(re_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 262252/262252 [00:35<00:00, 7425.55it/s]  \n"
     ]
    }
   ],
   "source": [
    "with open(\"text_final_final.txt\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "content = [word.strip() for word in content.split()]\n",
    "dict_words = {}\n",
    "\n",
    "for word in tqdm(content):\n",
    "    if word not in list(dict_words.keys()):\n",
    "        repetitions = content.count(word)\n",
    "        rep_list = [word for i in range(repetitions)]\n",
    "        dict_words[word] = rep_list\n",
    "        \n",
    "    else:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clases 6079\n",
      "['clases', 'danza', 'para', 'arabe', 'dance', 'yoga', 'miguel', 'baile', 'danzas', 'ni', 'gran', 'santiago', 'salsa', 'como', 'arabes', 'academia', 'metro', 'avenida', 'ballet', 'cursos']\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "dict_final = {}\n",
    "\n",
    "for k in sorted(dict_words, key=lambda k: len(dict_words[k]), reverse=True):\n",
    "    dict_final[k] = dict_words[k]\n",
    "    counter += 1\n",
    "    \n",
    "    if counter >= 150:\n",
    "        break\n",
    "        \n",
    "print(list(dict_final.keys())[0], len(dict_final[list(dict_final.keys())[0]]))\n",
    "list_final = []\n",
    "last_lenght = len(dict_final[list(dict_final.keys())[-1]])\n",
    "\n",
    "for key in dict_final.keys():\n",
    "    list_final.extend(dict_final[key][0:len(dict_final[key])-last_lenght])\n",
    "    \n",
    "str_final = ' '.join(list_final)\n",
    "\n",
    "text_file = open(\"esta si.txt\", \"w\", encoding=\"utf-8\")\n",
    "text_file.write(str_final)\n",
    "text_file.close()\n",
    "\n",
    "print([word for word in list(dict_final.keys())[0:20]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113420\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "final_list = []\n",
    "counter = 0\n",
    "\n",
    "for key in dict_words.keys():\n",
    "    \n",
    "    if len(dict_words[key]) > 100:\n",
    "        final_list.extend(dict_words[key])\n",
    "        counter += 1\n",
    "    \n",
    "    elif counter >= 150:\n",
    "        break\n",
    "        \n",
    "print(len(final_list))\n",
    "\n",
    "str_final = ' '.join(final_list)\n",
    "\n",
    "text_file = open(\"text_final_final_final.txt\", \"w\", encoding=\"utf-8\")\n",
    "text_file.write(str_final)\n",
    "text_file.close()\n",
    "\n",
    "print([word for word in ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262252\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "final = []\n",
    "\n",
    "for i, word in enumerate(re_list):\n",
    "    try:\n",
    "        re_word = re.search('([A-Za-z]+)', word).group(1)\n",
    "        final.append(re_word)\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(len(final))\n",
    "str_final = ' '.join(final)\n",
    "\n",
    "text_file = open(\"text_final_final.txt\", \"w\", encoding=\"utf-8\")\n",
    "text_file.write(str_final)\n",
    "text_file.close()\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client, LocalCluster, progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:62831</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>3</li>\n",
       "  <li><b>Cores: </b>6</li>\n",
       "  <li><b>Memory: </b>17.02 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:62831' processes=3 threads=6, memory=17.02 GB>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\anaconda3\\lib\\site-packages\\distributed\\worker.py:3387: UserWarning: Large object of size 3.48 MB detected in task graph: \n",
      "  (['', '+56945218625', 'danzaarabe@bellydancercl',  ... iles?'], '', 0)\n",
      "Consider scattering large objects ahead of time\n",
      "with client.scatter to reduce scheduler burden and \n",
      "keep data on workers\n",
      "\n",
      "    future = client.submit(func, big_data)    # bad\n",
      "\n",
      "    big_future = client.scatter(big_data)     # good\n",
      "    future = client.submit(func, big_future)  # good\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-171-71a7ed9731b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#round(len(list_words)/6))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mfutures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduce_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-171-71a7ed9731b8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#round(len(list_words)/6))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mfutures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduce_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\distributed\\client.py\u001b[0m in \u001b[0;36msubmit\u001b[1;34m(self, func, key, workers, resources, retries, priority, fifo_timeout, allow_other_workers, actor, actors, pure, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1576\u001b[0m             \u001b[0mdsk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mskey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1578\u001b[1;33m         futures = self._graph_to_futures(\n\u001b[0m\u001b[0;32m   1579\u001b[0m             \u001b[0mdsk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1580\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[0mskey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\distributed\\client.py\u001b[0m in \u001b[0;36m_graph_to_futures\u001b[1;34m(self, dsk, keys, restrictions, loose_restrictions, priority, user_priority, resources, retries, fifo_timeout, actors)\u001b[0m\n\u001b[0;32m   2581\u001b[0m                 \u001b[0mdsk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHighLevelGraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_collections\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdsk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2583\u001b[1;33m             \u001b[0mdsk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhighlevelgraph_pack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeyset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2585\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mretries\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\distributed\\protocol\\highlevelgraph.py\u001b[0m in \u001b[0;36mhighlevelgraph_pack\u001b[1;34m(hlg, client, client_keys)\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[1;34m\"__module__\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;34m\"__name__\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m                 \"state\": _materialized_layer_pack(\n\u001b[0m\u001b[0;32m    100\u001b[0m                     \u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                     \u001b[0mhlg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_all_external_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\distributed\\protocol\\highlevelgraph.py\u001b[0m in \u001b[0;36m_materialized_layer_pack\u001b[1;34m(layer, all_keys, known_key_dependencies, client, client_keys)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mall_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mdsk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mstringify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstringify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclusive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_keys\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdsk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mdsk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdumps_task\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdsk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"dsk\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdsk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dependencies\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"annotations\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mannotations\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\cytoolz\\dicttoolz.pyx\u001b[0m in \u001b[0;36mcytoolz.dicttoolz.valmap\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\cytoolz\\dicttoolz.pyx\u001b[0m in \u001b[0;36mcytoolz.dicttoolz.valmap\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\distributed\\worker.py\u001b[0m in \u001b[0;36mdumps_task\u001b[1;34m(task)\u001b[0m\n\u001b[0;32m   3369\u001b[0m                 \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"kwargs\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwarn_dumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3370\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3371\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_maybe_complex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3372\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"function\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdumps_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"args\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mwarn_dumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3373\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mto_serialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\distributed\\utils.py\u001b[0m in \u001b[0;36m_maybe_complex\u001b[1;34m(task)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[0mistask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m         \u001b[1;32mand\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_maybe_complex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m         \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_maybe_complex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\distributed\\utils.py\u001b[0m in \u001b[0;36m_maybe_complex\u001b[1;34m(task)\u001b[0m\n\u001b[0;32m    751\u001b[0m     return (\n\u001b[0;32m    752\u001b[0m         \u001b[0mistask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m         \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_maybe_complex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "def gen_chunks(combs, sample, size):\n",
    "    if isinstance(combs, dict):\n",
    "        combs = list(combs.keys())\n",
    "        \n",
    "    if sample == None:\n",
    "        sampled_list = combs\n",
    "    else:\n",
    "        sampled_list = combs[sample[0]:sample[1]]\n",
    "\n",
    "    for i in range(0, len(sampled_list), size):\n",
    "        yield sampled_list[i:i + size]\n",
    "\n",
    "\n",
    "def reduce_words(list_words, chunk, word, pos):\n",
    "    returns = []\n",
    "    \n",
    "    for i, word in enumerate(chunk):\n",
    "        local = copy.deepcopy(list_words)\n",
    "        local.pop(pos + i)\n",
    "        \n",
    "        if word in local:\n",
    "            returns.append(word)\n",
    "        \n",
    "        del local\n",
    "        \n",
    "    return returns\n",
    "        \n",
    "\n",
    "all_text = ''.join([value[1] for value in dict_texts.values()])\n",
    "list_words = all_text.split(' ')\n",
    "\n",
    "chunks = gen_chunks(list_words, [0, 1000], 100) #round(len(list_words)/6))\n",
    "\n",
    "futures = [client.submit(reduce_words, list_words, chunk, word, pos) for pos, word in enumerate(list_words)]\n",
    "results = client.gather(futures)\n",
    "\n",
    "    \n",
    "#final = ''.join(clean)\n",
    "\n",
    "#print(len(final))\n",
    "#text_file = open(\"texts.txt\", \"w\", encoding=\"utf-8\")\n",
    "#text_file.write(all_text)\n",
    "#text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://nataliadufuur.com/', 'http://www.danaamar.com/', 'http://www.nurdeoriente.cl/', 'http://www.nayra.cl/', 'https://www.bellydancer.cl/', 'http://danzaarabechile.cl/', 'https://www.lovebellydanceonline.com/', 'https://www.safidanzaarabe.com/?fbclid=IwAR0h4x7enqP0LILu8vNccaSS1kQL_hDvbL-Lejj3vNbcZyP5230jbiwCjCc', 'https://danzadelvientretribal.cl/', '', 'http://www.seyyalbellydancer.com/', 'https://danielabellydancer.com/', 'http://natalia-abdallah.com/clases-de-danzas-arabes-online/?gclid=Cj0KCQiAhP2BBhDdARIsAJEzXlGmqQCPdOZG7e8rQLKgdyNNXWwuq-9EI8Ghvjq8Swgw1xJxl2eQlyIaAuHhEALw_wcB', 'https://orientaldanceonline.com/', 'https://www.danzaire.cl/clases-de-baile-en-santiago/clases-de-danza-arabe/', 'https://clasessanmiguel.blogspot.com/', '', 'http://buscadanza.cl/', 'https://www.artfitcenter.cl/danza-arabe/', 'https://www.arabesca.cl/?fbclid=IwAR2I1sQLi9yI1LaIeiG0u7a97Wls1Gaq4Ih8YPTVTyDRJzzBS4ZYkru0p_M', 'https://www.sandricastillo.com/', '', 'https://academiazamia.blogspot.com/?fbclid=IwAR2rONEJccxUky8RiXU2APmkCsficG4JEpTOizuKF5oSPHDvvhYNgtIcLtk']\n",
    "dict_texts = {}\n",
    "\n",
    "for url in tqdm(urls):\n",
    "    try:\n",
    "        basic_url = re.search('(.*\\.com|.*\\.cl)', url).group(1)\n",
    "        dict_texts[basic_url] = get_text(basic_url)\n",
    "        \n",
    "        file_name = re.search('(https://www\\.|http://www\\.|https://|http://)(.*)\\.', basic_url).group(2)\n",
    "        \n",
    "        text_file = open(f'{file_name}.txt', \"w\", encoding=\"utf-8\")\n",
    "        text_file.write(dict_texts[basic_url])\n",
    "        text_file.close()\n",
    "        \n",
    "        print(file_name, basic_url)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(url, ' failed by ', e)\n",
    "        pass\n",
    "    \n",
    "all_texts = str(', '.join(list(dict_texts.values())))\n",
    "\n",
    "text_file = open(\"texts.txt\", \"w\", encoding=\"utf-8\")\n",
    "text_file.write(all_texts)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
